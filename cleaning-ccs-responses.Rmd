---
title: "CCS Analysis Template"
author: "Corey Jackson"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Import example data
library(readr)
library(reshape2)
library(dplyr)
library(tidygeocoder)
library(tidycensus)
library(tidyverse)
library(googleLanguageR)
library(cld2)
library(datasets)
library(textstem)
library(tidytext)
library(DT)


gl_auth("/Volumes/cbjackson2/ccs-knowledge/translate-ccs-ac3757553e16.json")
gl_auto_auth()
###########################################################
####### IMPORT/COMBINE DATASETS FROM RESEARCH DRIVE #######
###########################################################

########## URBAN HEAT ########## 


# Import file survey and map files from Research Drive. Ignore the first 7 lines that have metadata for the element
heat_survey <- read_csv("/Volumes/cbjackson2/ccs-knowledge/ccs-data/urban-heat/heat_survey.csv") # move to Zoonvierse Datasets folder
heat_survey <- heat_survey[,-1]

heat_translate <- heat_survey %>% 
  select(c(4,8,11))%>%
  mutate(across(everything(), ~ gl_translate(.x, target = "en") )
  ) 

# TRANSLATIONS
heat_survey <- heat_survey %>%
  mutate(
    `Have you or anyone you know experienced health issues related to urban heat (e.g., heat exhaustion, heat stroke) in the past year? If so, please tell us a bit about the persons' experiences.` = NULL,
    `Have you or anyone you know experienced health issues related to urban heat (e.g., heat exhaustion, heat stroke) in the past year? If so, please tell us a bit about the persons' experiences.`=
      heat_translate[[1]]$translatedText,.after=3) %>%
  mutate(  
    `What can local government do to help mitigate urban heat in your community?` = NULL,
    `What can local government do to help mitigate urban heat in your community?`=
      heat_translate[[2]]$translatedText,.after=7) %>%
  mutate(
    `In order to become more informed about urban heat and mitigation strategies, what specific information would you require?` = NULL,
    `In order to become more informed about urban heat and mitigation strategies, what specific information would you require?`=
      heat_translate[[3]]$translatedText,.after=10
  )

```

There are four types of questions, we asked in the CCS surveys, the Knowledge Map will need to detect the question type and conduct analysis based on the type of question present

#### Short/long Text Questions

These questions are open ended and include text responses. The set of questions will be cleaned using text mining procedures and then analyzed using bag of words and sentiment. The presentation of responses will be word clouds and sentiment by the demographic factors. Example question is Heat Survey Q1 "Have you or anyone you know experienced health issues related to urban heat (e.g., heat exhaustion, heat stroke) in the past year? If so, please tell us a bit about the persons' experiences."

##### Cleaning Open-ended Response Data 

```{r cleaning-openended-response}

# https://www.tidytextmining.com/index.html 
# https://paldhous.github.io/NICAR/2019/r-text-analysis.html 

# Import stoplist 
malletwords <- scan("/Volumes/cbjackson2/ccs-knowledge/ccs-data/report_data/mallet.txt", character(), quote = "")

# Extract example question and demographic data

example_open <- heat_survey[,c(2,4,45:53,19)]
names(example_open)[2] <- "response" 

example_open$response_cleaned <- tolower(gsub('[[:punct:]]', ' ', example_open$response))
#response$cleaned <- removeWords(response$cleaned, c(stopwords("english"),malletwords))
#response$cleaned <- lemmatize_words(response$cleaned)

# Tokenize response_cleaned to create word cloud and summary responses by demographic groups
unigram_response <- example_open %>% 
  unnest_tokens(unigram, 
                response_cleaned, token = "ngrams", n = 1)

# Melt data
unigram_response.m <- unigram_response %>%
  pivot_longer(!`Contribution ID`:Gender, names_to = "tokens", values_to = "words")

# Summarize data by demographic factors - Gender, Hipanic/Latino/Spanish Origin, Race / Ethnicity, Year of Birth, Annual Household Income level, Education Level

unigram_summary <- unigram_response.m %>% 
  group_by(Gender,words) %>% 
  count()


###### Bi-gram responses
bigram_response <- example_response %>% 
  unnest_tokens(unigram, 
                response_cleaned, token = "ngrams", n = 2)

bigram_response.m <- bigram_response %>%
  pivot_longer(!response:Gender, names_to = "tokens", values_to = "words")

bigram_summary <- bigram_response.m %>% 
  group_by(Gender,words) %>% 
  count()


# Add sentiment to text ...  https://www.datacamp.com/tutorial/sentiment-analysis-R
```

##### Reporting Open Ended Responses

```{r reporting-openended-response}

datatable(unigram_summary)

datatable(bigram_summary)

```

#### Matrix Questions

Example question is Heat Survey Q2 "Please rate how frequently you have done each of the following during summer months and during extreme heat."

##### Cleaning Matrix Responses  

Detection might involve extracting the first four words of every response, if they all match, then the response is a multi-choice data object. 

```{r cleaning-matrix-response}
example_matrix <- heat_survey[,c(2,5,45:53,19)]
names(example_matrix)[2] <- "response" 

# Since the questions are in one column, we need to seperate them and then the question and respone variables
example_matrix <- example_matrix %>% 
  separate_rows(response, sep = "; ") %>%
  separate(response, into = c("question", "answer"), sep = " - ")
  
matrix_summary <- example_matrix %>% 
  group_by(Gender,question,answer) %>% 
  count()


```


##### Reporting Matrix Responses  
```{r}
datatable(matrix_summary)
```


#### Multi-Choice Questions

##### Cleaning Multi-Choice Responses 
```{r}
example_multi <- heat_survey[,c(2,7,45:53,19)]
names(example_multi)[2] <- "response" 

example_multi <- example_multi %>% 
  separate_rows(response, sep = "; ")

# Also extract other and run topic modeling? 
  
multi_summary <- example_multi %>% 
  group_by(Gender,response) %>% 
  count()

```

##### Reporting Multi-Choice Responses 
```{r}
datatable(multi_summary)
```


#### Select Box Questions

##### Cleaning Select Box Responses 
```{r}

```

##### Reporting Select Box Responses 
```{r}

```


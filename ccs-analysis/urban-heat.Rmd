---
title: 'CCS Knowlede Map Results: Urban Heat'
author: "Corey Jackson"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
---


```{r setup, include=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(DT)
library(ggsci)
library(gridExtra)
library(stringr)
library(broom) # For tidy chi-squared test results
library(stm)

potential_fakes <- c(316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 327, 329,
                     330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 
                     346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 358, 359, 360, 361, 
                     362, 363, 364, 365, 366, 367, 369, 370, 371, 372, 373, 374, 376, 378, 379, 380,
                     381, 382, 383, 384, 385, 389, 390, 391, 392, 392, 393, 395, 396, 397, 398, 399)

heat_survey <- read.csv("/Volumes/cbjackson2/ccs-knowledge/ccs-data/urban-heat/heat_survey.csv")
heat_map <- read.csv("/Volumes/cbjackson2/ccs-knowledge/ccs-data/urban-heat/heat_map.csv")

# Questions - https://docs.google.com/document/d/1hl5Eb66a8j7TDE1EzzOF4eUjUguet5dMsw7UJydr_uY/edit
heat_survey <- heat_survey %>%
  distinct(Contribution.ID, .keep_all = TRUE)


### ### ### ### ### ### ### ### ### ## 
### Functions for MATRIX QUESTIONS ### 
### ### ### ### ### ### ### ### ### ##

clean_matrix <- function(dataframe, column_name) {
  cleaned_data <- dataframe %>%
    separate_rows({{ column_name }}, sep = "; ") %>%
    separate({{ column_name }}, into = c("question", "answer"), sep = " - ")
  cleaned_data$answer <- as.factor(cleaned_data$answer)
  
  summary_data <- cleaned_data %>%
    group_by(question, answer) %>%
    summarise(n = n()) %>%
    mutate(freq = round((n / sum(n)),digits=2     )*100)
  
  return(summary_data)
}

viz_matrix <- function(dataframe, graph_title) {
  ggplot(dataframe, aes(x=question, y=freq, fill=answer)) +
    geom_bar(stat="identity", position="stack") +
    theme_minimal() +
    scale_x_discrete(labels = function(x) str_wrap(x, width = 40)) + # Wrap labels to a width of 5 words
    coord_flip() +
    labs(title=graph_title,
         x="Question",
         y="Frequency (%)",
         fill="Answer") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_fill_nejm()
}

## clean_matrix with variable
clean_matrix_eval <- function(dataframe, column_name, demographic_var) {
  cleaned_data <- dataframe %>%
    separate_rows({{ column_name }}, sep = "; ") %>%
    separate({{ column_name }}, into = c("question", "answer"), sep = " - ")
  cleaned_data$answer <- as.factor(cleaned_data$answer)
  
  summary_data <- cleaned_data %>%
    group_by( {{demographic_var}},question,answer) %>%
    summarise(n = n()) %>%
    mutate(freq = round((n / sum(n)),digits=2     )*100)
  
  return(summary_data)
}

## clean_matrix with variable
clean_matrix_eval_viz <- function(dataframe, demographic_var) {
   ggplot(dataframe, aes(x = !!sym(demographic_var), y = freq, fill = answer)) +
    geom_bar(stat = "identity", position = "fill") +  # Use 'fill' to stack the bars to 100%
    scale_y_continuous(labels = scales::percent_format()) +  # Use percent format for y-axis labels
    labs(y = "Percentage", x = "Vulnerability Level", fill = "Answer") +
    coord_flip() +  # Flip the axes to have vulnerability level on the y-axis
    theme_minimal() +
    theme(axis.text.x = element_text(hjust = 1)) +
 scale_fill_nejm()
}


### ### ### ### ### ### ### ### ### 
### Functions for BOX QUESTIONS ### 
### ### ### ### ### ### ### ### ### 

clean_box <- function(data, response) {
  summary_data <- data %>%
    group_by({{ response }}) %>%
    summarise(count = n()) %>%
    mutate(freq = round(count / sum(count), digits = 2)*100)
    names(summary_data)[1] <- "response"

  return(summary_data)
}

clean_box_eval <- function(data, column_name, demographic_var) {

# Calculate the total number of responses per vulnerable category
people <- air_survey_experiences %>%
  group_by({{demographic_var}}) %>%
  summarise(total = n())

# Calculate the summary data including frequencies
summary_data <- air_survey_experiences %>%
    group_by({{demographic_var}}, {{column_name}}) %>%
    summarise(n = n()) 

summary_data <- merge(summary_data,people, by = "vulnerable")

summary_data <- summary_data  %>%
  mutate(freq = round((n / total), digits = 2) * 100)

return(summary_data)
}




### ### ### ### ### ### ### ### ### #
### Functions for MULTI QUESTIONS ### 
### ### ### ### ### ### ### ### ### #

clean_multi <- function(data, response) {
  cleaned_data <- data %>%
    separate_rows({{ response }}, sep = "; ")
  
  summary_data <- cleaned_data %>%
    group_by({{ response }}) %>%
    summarise(count = n()) %>%
    mutate(freq = round(count / dim(data)[1], digits = 2) * 100)
      names(summary_data)[1] <- "response"

  return(summary_data)
}

clean_multi_eval <- function(data, column_name, demographic_var) {

# Calculate the total number of responses per vulnerable category
people <- data %>%
  group_by({{demographic_var}}) %>%
  summarise(total = n())


# Clean the data by separating rows and columns as required
cleaned_data <- data %>%
  separate_rows({{ column_name }}, sep = "; ") %>%
  separate({{ column_name }}, into = c("question"), sep = " - ")
print(cleaned_data)


# Calculate the summary data including frequencies
summary_data <- cleaned_data %>%
  #group_by({{demographic_var}}, question) %>%
  group_by(vulnerable, question) %>%
  summarise(n = n(), .groups = 'drop')

summary_data <- merge(summary_data,people, by = "vulnerable")

summary_data <- summary_data  %>%
  mutate(freq = round((n / total), digits = 2) * 100)

return(summary_data)
}

viz_clean_multi_eval <- function(dataframe,graph_title) {
 
  # Create the bar chart
   # Create the bar chart with differentiation for 'vulnerable' levels within each 'question'
  ggplot(dataframe, aes(x=reorder(question, -freq), y=freq, fill=vulnerable)) +
    geom_bar(stat="identity", position="dodge") + # Use 'position=dodge' to place bars side by side
    theme_minimal() +
    scale_x_discrete(labels = function(x) str_wrap(x, width = 40)) + # Wrap labels to a width of 40 characters
    coord_flip() +
    labs(title=graph_title,
         x="Response",
         y="Frequency (%)") +
    scale_fill_brewer(palette="Set1") + # Use a Brewer palette for distinguishable colors
    theme(axis.text.x = element_text(angle=45, hjust=1))
}

clean_matrix_eval_viz_all <- function(dataframe) {
   ggplot(dataframe, aes(x = vulnerable, y = freq, fill = answer)) +
    geom_bar(stat = "identity", position = "fill") +  # Use 'fill' to stack the bars to 100%
    scale_y_continuous(labels = scales::percent_format()) +  # Use percent format for y-axis labels
    labs(y = "Percentage", x = "Vulnerability Level", fill = "Answer") +
    facet_wrap(~ question, scales = "free", ncol = 1) +  # Facet by the question variable
    coord_flip() +  # Flip the axes to have vulnerability level on the y-axis
    theme_minimal() +
    theme(axis.text.x = element_text(hjust = 1)) +
    scale_fill_nejm() +
    theme(strip.text.y = element_text(angle = 0))  # Make facet labels horizontal
}

####

viz_box_multi <- function(dataframe,graph_title) {
  # Order the dataframe by decreasing frequency
  ordered_df <- dataframe %>%
    arrange(desc(freq))
  
  # Create the bar chart
  ggplot(ordered_df, aes(x=reorder(response, -freq), y=freq)) +
    geom_bar(stat="identity", fill="blue") +
    theme_minimal() +
    scale_x_discrete(labels = function(x) str_wrap(x, width = 40)) + # Wrap labels to a width of 5 words
    coord_flip() +
    labs(title=graph_title,
         x="Response",
         y="Frequency (%)") +
    theme(axis.text.x = element_text(angle=45, hjust=1))+
scale_fill_nejm()
}

### STATS ANALYSIS
clean_matrix_eval_chi <- function(questions_df) {
  results_list <- list() # Initialize an empty list to store the results dataframes
  
  # Loop through each unique question in the questions dataframe
  for(i in unique(questions_df$question)){
    data <- questions_df %>% filter(question == i)
    
    # Assuming 'vulnerable' is a column in your 'data' dataframe for categorization
    # You may need to adjust 'vulnerable' to the actual column name in 'summary_data'
    contingency_table <- xtabs(n ~ answer + vulnerable, data = data)
    chi_squared_test <- chisq.test(contingency_table,correct = TRUE)
    
    # Create a dataframe with the Chi-Squared test results
    results_df <- data.frame(
      question = i,
      statistic = chi_squared_test$statistic,
      pvalue = chi_squared_test$p.value,
      degreeof = chi_squared_test$parameter
    )
    
    # Store the results dataframe in the list
    results_list[[i]] <- results_df
  }
  
  # Combine all result dataframes in the list into a single dataframe
  final_results_df <- do.call(rbind, results_list)
  
  return(final_results_df)
}


clean_multi_eval_chi <- function(dataframe) {
  # Ensure 'n' is treated as numeric
  dataframe$n <- as.numeric(dataframe$n)
  
  results <- dataframe %>%
    group_by(question) %>%
    summarise(Least = sum(n[vulnerable == "Least"]),
              Most = sum(n[vulnerable == "Most"])) %>%
    rowwise() %>%
    do({
      chi_test_result <- chisq.test(c(.$Least, .$Most),correct = TRUE)
      data.frame(question = .$question,
                 statistic = round(chi_test_result$statistic, 3),
                 pvalue = round(chi_test_result$p.value, 3),
                 degreeof = round(as.numeric(chi_test_result$parameter), 3))
    }) %>%
    ungroup()
  
  return(results)
}

perform_topic_modeling <- function(df, attribute_name) {

    # Lists to store plots and thoughts data frames
    plots_list <- list()
    thoughts_list <- list()
    
    for (attr_val in unique(df[[attribute_name]])) {
  
        #sub_df <- df[which(df[[attribute_name]] == attr_val),]
             sub_df <- vulnerable_q1[which(vulnerable_q1["vulnerable"] == "Most"),]

        # Repeat the preprocessing and topic modeling steps for sub_df
        processed_texts <- textProcessor(documents=vulnerable_q1$text_column, metadata=vulnerable_q1)
        out <- prepDocuments(processed_texts$documents, processed_texts$vocab, processed_texts$meta)
        docs <- out$documents
        vocab <- out$vocab
        meta <- out$meta

        # Fit the topic model for the subgroup
        topic_model <- stm(documents=docs, vocab=vocab, K=2, data=meta, max.em.its=10, init.type="Spectral")
        
        # Create a new plot window, plot, and then store the plot using recordPlot
        plot_name <- paste0(attribute_name, "_", attr_val, "_plot")
        
        plot.new()
        plot(topic_model, type="summary", main=paste("Topic Model Summary -", attr_val, "Vulnerable"))
        plots_list[[plot_name]] <- recordPlot()
        dev.off()  # Close the plotting window
     

        # Then, pass these texts to 'findThoughts'
        thoughts <- findThoughts(topic_model, texts=modeled_texts, topics=c(1,2), n=3)
        # Create a dataframe for thoughts and add attribute information
        thoughts_sub_df <- data.frame(stack(thoughts$docs))
        names(thoughts_sub_df)[1:2] <- c("Attribute","Thoughts")
        thoughts_sub_df$type <- attr_val
        
        # Add to the list of thoughts dataframes
        thoughts_list[[paste0(attribute_name, "_", attr_val, "_thoughts")]] <- thoughts_sub_df  
    }
    
    # Combine all thoughts data frames into one
    all_thoughts_df <- do.call("rbind", thoughts_list)
    
    # Return a list containing both the plots and the combined thoughts dataframe
    return(list("plots" = plots_list, "thoughts" = all_thoughts_df))
}


names(heat_survey)[5:12] <- c("urban_heat_experience",
    "summer_activity_frequency",
    "disproportionate_heat_impact",
    "personal_heat_actions",
    "government_heat_mitigation",
    "heat_information_sources",
    "community_heat_participation",
    "heat_education_needs")

```

## Urban Heat (UH)
```{r uh-setup, include=FALSE, cache=TRUE}

summer_activity_frequency <- clean_matrix(heat_survey, summer_activity_frequency)
summer_activity_frequency_viz <- viz_matrix(summer_activity_frequency, "Summer Activity Frequency")

personal_heat_actions <- clean_multi(heat_survey, personal_heat_actions)
personal_heat_actions_viz <- viz_box_multi(personal_heat_actions, "Personal Heat Actions")

heat_information_sources <- clean_multi(heat_survey, heat_information_sources)
heat_information_sources_viz <- viz_box_multi(heat_information_sources,"Heat Information Sources")

community_heat_participation <- clean_multi(heat_survey, community_heat_participation)
community_heat_participation_viz <- viz_box_multi(community_heat_participation, "Community Heat Participation")
```

- Description of survey and the questions asked

### UH Analysis
```{r uh-analysis-report, echo=TRUE}

```

### Please rate how frequently you have done each of the following during summer months and during extreme heat.
```{r}
datatable(summer_activity_frequency)
summer_activity_frequency_viz
```


### Which of the following personal steps have you taken to reduce your contribution to urban heat and reduce greenhouse emissions?
```{r}
datatable(personal_heat_actions)
personal_heat_actions_viz
```


### Where do you currently go for information about heat (waves)? And how do you usually learn about extremely hot weather?
```{r}
datatable(heat_information_sources)
heat_information_sources_viz
```


### Are you interested in participating in community-based efforts to address urban heat in your neighborhood?
```{r}
datatable(community_heat_participation)
community_heat_participation_viz
```

 

## Place Analysis for Tree Canopies
```{r place-analysis, include=FALSE, cache=FALSE}

# The EJ dataframe has descriptions of their neighborhoods, we could examine perceptions and solutions. We might need to highlight contrasting (interesting) insights. Depending on match, we could make argument for more knowledge about harms

# tree_survey <- tree_survey %>%
#   mutate(
#     county_code = sprintf("%03d", as.integer(county_fips)),
#     census_tract = sprintf("%06d", as.integer(census_tract)),
#     census_block = sprintf("%04d", as.integer(census_block)),
#     census_tract_full = paste0(state_fips, county_code, census_tract),
#     census_block_full = paste0(state_fips, county_code, census_tract, census_block),
#   )

data_tracts <- c(unique(heat_survey$census_tract_full))
data_blocks <- c(unique(heat_survey$census_block_full))

# https://www.atsdr.cdc.gov/placeandhealth/svi/index.html
#svi_tract <- read.csv("/Volumes/cbjackson2/ccs-knowledge/census-data/svi/svi-wi-tract.csv")
#svi_response <- svi_tract[which(svi_tract$FIPS %in% data_tracts),]

# Which variables are important to include in the analysis?

#https://www.atsdr.cdc.gov/placeandhealth/eji/indicators.html
eji <- read.csv("//Volumes/cbjackson2/ccs-knowledge/census-data/environmental/eji-wisconsin.csv")
#eji <- eji[which(!is.na(eji$RPL_EBM)),]
eji <- eji[which(eji$COUNTY %in% c("Dane","Jefferson")),]

# Calculate quartiles
Q1 <- quantile(eji$RPL_EBM, 0.25,na.rm = TRUE)
Q3 <- quantile(eji$RPL_EBM, 0.75,na.rm = TRUE)

data_tracts[which(!data_tracts %in% eji$geoid)]


eji_response <- eji[which(eji$geoid %in% data_tracts),]
eji_response$vulnerable <- ifelse(eji_response$RPL_EBM > Q3, "Least","Most")
eji_response_analysis <- eji_response %>%
  dplyr::select(OBJECTID,statefp,countyfp,tractce,affgeoid,geoid,name,COUNTY,StateAbbr,StateDesc,Location,E_TOTPOP,SPL_EJI,RPL_EJI,RPL_EBM,EPL_OZONE,EPL_PM,EPL_DSLPM,EPL_TOTCR,SPL_EBM_THEME1,RPL_EBM_DOM1,vulnerable)
# Which indicators are important to include in the analysis? 

# Indicators: https://www.atsdr.cdc.gov/placeandhealth/eji/docs/EJI-2022-Indicators-508.pdf 
# Dictionary: https://eji.cdc.gov/Documents/Data/2022/EJI_2022_Data_Dictionary_508.pdf
# EJI -> Environmental Burden -> Air Pollution-> ALL (Ozone EPL_OZONE  ,PM2.5 EPL_PM  ,Disel Particulate Matter EPL_DSLPM, Air Toxic Cancer Risks EPL_TOTCR)
#   SPL_EBM_THEME1: Domain consisting of ozone, PM2.5, air toxics cancer risk, and diesel particulate matter. 
#   RPL_EBM_DOM1: Percentile rank of domain consisting of ozone, PM2.5, air toxics cancer risk, and diesel particulate matter.
# EJI -> Environmental Burden -> Built Environment -> (Recreational Parks)

# SPL_EJI: Summation of the HVM, EBI, and SVI module percentile ranks 
# RPL_EJI: Percentile ranks of SPL_EJI

eji_response_analysis$E_TOTPOP <- as.numeric(gsub(",", "", eji_response_analysis$E_TOTPOP))


#https://www.epa.gov/ejscreen/understanding-ejscreen-results
#ejscreen <- read.csv("/Volumes/cbjackson2/ccs-knowledge/census-data/environmental/ejm-wisconsin.csv")
#ejscreen_response <- ejscreen[which(ejscreen$Census.tract.2010.ID %in% data_tracts),]

# Which variables are important to include in the analysis?


#The first 2 digits represent the state FIPS (Federal Information Processing Standards) code.
#The next 3 digits are for the county within that state.
#Following 6 digits are for the census tract within the county.
#The next 1 to 4 digits (of which you're interested in the first part) represent the block group or block, which are subdivisions of census tracts.
######### Decide which tracts are vulnerable. Make respondents in two groups.
```

### Categorizing Vulnerability 
```{r vulnerability, eval=TRUE, include=FALSE}
# Summarize our data

summary_eji <- eji_response_analysis %>%
  group_by(vulnerable) %>%
  summarise(across(.cols = 12:21, .fns = list(mean = ~mean(.x, na.rm = TRUE))))

summary_eji <- summary_eji %>% mutate_if(is.numeric, round, 3)

library(sf)          # for handling spatial data
library(tigris)
options(tigris_use_cache = TRUE)
options(scipen=999)


# Load the shapefile
#wisconsin_blocks <- st_read("/Volumes/cbjackson2/ccs-knowledge/ccs-data/geography/WI_CensusTL_BlockGroups_2020/WI_CensusTL_BlockGoups_2020.shp")

wisconsin_tract <- st_read("/Volumes/cbjackson2/ccs-knowledge/ccs-data/geography/tl_2018_55_tract/tl_2018_55_tract.shp")

# Filter to include only your tracts
#tree_survey$census_block_group <- substr(tree_survey$census_block_full, start = 1, stop = 12)
# Ensure the 'GEOID' format matches that of your dataframe and adjust "geoid" accordingly
target_tracts <- c(unique(heat_survey$census_tract_full))

# Convert your 'geoid' values to character if they are not already, to ensure matching works
wisconsin_tracts_filtered <- wisconsin_tract %>%
    filter(as.character(GEOID) %in% target_tracts)

eji_response_analysis$geoid <- as.character(eji_response_analysis$geoid)

wisconsin_tracts_filtered <- left_join(wisconsin_tracts_filtered,eji_response_analysis[c("geoid","RPL_EJI","vulnerable")], by =c("GEOID"="geoid"))

# Plot using ggplot2
county_data <- ggplot() +
  geom_sf(data = wisconsin_tracts_filtered, aes(fill = RPL_EJI), color = "black") +
    scale_fill_gradient(low = "lightblue", high = "darkblue", name = "EJI ranking") + # Customize color scale as needed
  theme_minimal() +
   theme_bw() + theme(panel.border = element_blank(), 
                      panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank(), 
                      axis.line = element_blank(),
                      axis.text = element_blank(),
                      axis.ticks = element_blank()) +
  labs(title = "Environmental Burden Highlighted Census Tracts")
```

```{r}
county_data
```

In our analysis, we categorized vulnerability based on the Environmental Burden Module (RPL_EBM) percentile ranks derived from the 2022 Environmental Justice Index. To do this, we first determined the 25th (Q1) and 75th (Q3) percentile values of the RPL_EBM distribution. These percentile values served as thresholds to categorize regions based on their environmental burden. Specifically, regions with an RPL_EBM value greater than the 75th percentile (Q3) were categorized as "Most Vulnerable", indicating that they are in the top quartile of environmental burden and, therefore, face higher vulnerability to environmental injustices. Conversely, regions not exceeding this threshold were categorized as "Least Vulnerable". This method of categorization allows us to identify areas with the most significant environmental challenges and prioritize them for interventions and resource allocation.

```{r}
datatable(summary_eji)
```


```{r include=FALSE, warning=FALSE}
heat_survey$census_tract_full <- as.character(heat_survey$census_tract_full)
# Group people into least/most vulnerable areas 
heat_survey <- left_join(heat_survey, eji_response_analysis, by =c("census_tract_full"="geoid"))
heat_survey_experiences <- heat_survey
heat_survey_experiences <- heat_survey_experiences[which(!is.na(heat_survey_experiences$vulnerable)),]

# vulnerable_q1 <- data.frame(heat_survey_experiences$urban_heat_experience,heat_survey_experiences$vulnerable)
# names(vulnerable_q1)[1:2] <- c("text_column","vulnerable")
# vulnerable_q1_stm <- perform_topic_modeling(vulnerable_q1, "vulnerable")
# vulnerable_q1_stm_thoughts <-  data.frame(vulnerable_q1_stm$thoughts)
# rownames(vulnerable_q1_stm_thoughts) <- 1:dim(vulnerable_q1_stm_thoughts)[1]

### Add Questions analysis
vulnerable_q2 <- clean_matrix_eval(heat_survey_experiences, summer_activity_frequency,vulnerable)
vulnerable_q2 <- vulnerable_q2[which(!is.na(vulnerable_q2$vulnerable)),]
vulnerable_q2$answer <- factor(vulnerable_q2$answer, levels = rev(c("Always", "Often", "Sometimes", "Rarely","Never")))
vulnerable_q2_viz <- clean_matrix_eval_viz_all(vulnerable_q2)
vulnerable_q2_chi <- clean_matrix_eval_chi(vulnerable_q2)

# vulnerable_q3 <- data.frame(heat_survey_experiences$disproportionate_heat_impact,heat_survey_experiences$vulnerable)
# names(vulnerable_q3)[1:2] <- c("text_column","vulnerable")
# vulnerable_q3_stm <- perform_topic_modeling(vulnerable_q3, "vulnerable")
# vulnerable_q3_stm_thoughts <-  data.frame(vulnerable_q3_stm$thoughts)
# rownames(vulnerable_q3_stm_thoughts) <- 1:dim(vulnerable_q3_stm_thoughts)[1]

vulnerable_q4 <- clean_multi_eval(heat_survey_experiences, personal_heat_actions,vulnerable)
vulnerable_q4 <- vulnerable_q4[which(!is.na(vulnerable_q4$vulnerable)),]
vulnerable_q4_viz <- viz_clean_multi_eval(vulnerable_q4, "Personal Heat Actions")
vulnerable_q4_chi <- clean_multi_eval_chi(vulnerable_q4)

# vulnerable_q5 <- data.frame(heat_survey_experiences$government_heat_mitigation,heat_survey_experiences$vulnerable)
# names(vulnerable_q5)[1:2] <- c("text_column","vulnerable")
# vulnerable_q5_stm <- perform_topic_modeling(vulnerable_q5, "vulnerable")
# vulnerable_q5_stm_thoughts <-  data.frame(vulnerable_q5_stm$thoughts)
# rownames(vulnerable_q5_stm_thoughts) <- 1:dim(vulnerable_q5_stm_thoughts)[1]

vulnerable_q6 <- clean_multi_eval(heat_survey_experiences, heat_information_sources,vulnerable)
vulnerable_q6 <- vulnerable_q6[which(!is.na(vulnerable_q6$vulnerable)),]
vulnerable_q6_viz <- viz_clean_multi_eval(vulnerable_q6, "Heat Information Sources")
vulnerable_q6_chi <- clean_multi_eval_chi(vulnerable_q6)

vulnerable_q7 <- clean_multi_eval(heat_survey_experiences, community_heat_participation,vulnerable)
vulnerable_q7 <- vulnerable_q7[which(!is.na(vulnerable_q7$vulnerable)),]
vulnerable_q7_viz <- viz_clean_multi_eval(vulnerable_q7, "Community Heat Participation")
vulnerable_q7_chi <- clean_multi_eval_chi(vulnerable_q7)

# vulnerable_q8 <- data.frame(heat_survey_experiences$heat_education_needs,heat_survey_experiences$vulnerable)
# names(vulnerable_q8)[1:2] <- c("text_column","vulnerable")
# vulnerable_q8_stm <- perform_topic_modeling(vulnerable_q8, "vulnerable")
# vulnerable_q8_stm_thoughts <-  data.frame(vulnerable_q8_stm$thoughts)
# rownames(vulnerable_q8_stm_thoughts) <- 1:dim(vulnerable_q8_stm_thoughts)[1]
```

1  **Have you or anyone you know experienced health issues related to urban heat (e.g., heat exhaustion, heat stroke) in the past year? If so, please tell us a bit about the persons' experiences.**  

```{r}
#vulnerable_q1_stm$plots$vulnerable_Least_plot
```

```{r }
#vulnerable_q1_stm$plots$vulnerable_Most_plot
```

```{r }
#datatable(vulnerable_q1_stm_thoughts)
```

2. **Please rate how frequently you have done each of the following during summer months and during extreme heat on a scale from 1 to 5, where 1 means "Never" and 5 means "Always"** Required
 
```{r}
datatable(vulnerable_q2)
vulnerable_q2_viz
datatable(vulnerable_q2_chi)
```

3. **How are individuals disproportionately affected by urban heat in your community?** Required
```{r}
#vulnerable_q3_stm$plots$vulnerable_Least_plot
```

```{r }
#vulnerable_q3_stm$plots$vulnerable_Most_plot
```

```{r }
#datatable(vulnerable_q3_stm_thoughts)
```

4. **Which of the following personal steps have you taken to reduce your contribution to urban heat and reduce greenhouse emissions?** 
```{r}
datatable(vulnerable_q4)
vulnerable_q4_viz
datatable(vulnerable_q4_chi)
```

5. **What can local government do to help mitigate urban heat in your community?** Required
```{r}
#vulnerable_q5_stm$plots$vulnerable_Least_plot
```

```{r }
#vulnerable_q5_stm$plots$vulnerable_Most_plot
```

```{r }
#datatable(vulnerable_q5_stm_thoughts)
```

6. **Where do you currently go for information about heat (waves)? And how do you usually learn about extremely hot weather?** Required
```{r}
datatable(vulnerable_q6)
vulnerable_q6_viz
datatable(vulnerable_q6_chi)
```

7. **Are you interested in participating in community-based efforts to address urban heat in your neighborhood?**
```{r}
datatable(vulnerable_q7)
vulnerable_q7_viz
datatable(vulnerable_q7_chi)
```

8. **In order to become more informed about urban heat and mitigation strategies, what specific information would you require?** Required
```{r}
#vulnerable_q8_stm$plots$vulnerable_Least_plot
```

```{r }
#vulnerable_q8_stm$plots$vulnerable_Most_plot
```

```{r }
#datatable(vulnerable_q8_stm_thoughts)
```
